# 1. Suponga que $(x_1, y_1), ... , (x_n, y_n)$ son pares observados generados por los siguientes modelos. Deduzca los estimadores de m√≠nimos cuadrados de $\beta_1$ y $\beta_0$.

## a. $Y = \beta_1 x + \epsilon$

$\beta_0 = 0$ a partir de la definici√≥n del modelo de regresi√≥n $Y = \beta_0 + \beta_1x + \epsilon$, por lo que no es necesaria su estimaci√≥n.

Se quiere saber el valor de la recta de regresi√≥n verdadera en el punto $x=0$, a partir de la deducci√≥n de que la ordenada al origen es 0:

* $Y = \beta_1 0 + 0$ // *$\epsilon = 0$ porque es la recta de regresi√≥n verdadera*
* $Y = 0$

Por lo tanto, la recta pasa por el punto $(0,0)$.

### C√°lculo de desviaci√≥n vertical

$Altura Punto - Altura L√≠nea = y_i - (\beta_0 + \beta_1 x)$

En este caso, al ser una recta con ordenada al origen en 0, la altura de un punto $(x_i, y_i)$ est√° dada por $y_i$. La altura de la l√≠nea, por otro lado, est√° definida por el modelo; en este caso, por $\beta_1x$.

$y_i - \beta_1x_i = y_i-(\beta_0 + \beta_1x_i)$

$y_i - \beta_1x_i = y_i - (\beta_1x_i)$

Por lo tanto, la desviaci√≥n vertical est√° dada por:

$y_i - \beta_1x_i$

### C√°lculo de estimadores

A partir de la desviaci√≥n vertical puede definirse una funci√≥n $f$ para calcular la sumatoria de desviaciones al cuadrado:

$f(b_0,b_1) = \sum_{i=1}^n[y_i - (b_0 + b_1x_i)]^2$

$f(b_0,b_1) = \sum_{i=1}^n(y_i - b_0 - b_1x_i)^2$

Nuevamente, como se sabe que $\beta_0 = 0$, la funci√≥n puede reducirse a:

$f(0,b_1) = \sum_{i=1}^n(y_i - b_1x_i)^2$

### C√°lculo de derivadas parciales

$\dfrac {df(0,b_1)} {db_1} = \dfrac {d(\sum_{i=1}^n {(y_i - b_1x_i)}^2)} {db_1}$

$\dfrac {df(b_0,b_1)} {db_1} = -2 \sum _{i=1} ^n x_i(y_i-b_1x_i)$

A partir de esto, se buscar√° obtener un estimador puntual $\hat\beta_1$:

$\hat\beta_1 = -2 \sum _{i=1} ^n x_i(y_i-b_1x_i) = 0$

$\sum _{i=1} ^n x_i(y_i-b_1x_i) = 0$

$\sum _{i=1}^n (x_i.y_i) - \sum_{i=1}^n x_i.b_1.x_i = 0$

$\sum _{i=1}^n (x_i.y_i) = \sum_{i=1}^n x_i^2.b_1$

$\sum _{i=1}^n (x_i.y_i) = b_1 \sum_{i=1}^n x_i^2$

$\hat\beta_1 = \dfrac {\sum _{i=1}^n (x_i.y_i)} {b_1 \sum_{i=1}^n x_i^2}$

## b. $Y = \beta_1(ax+c) + \beta_0 + \epsilon$

A partir del modelo de regresi√≥n $Y = \beta_0 + \beta_1x + \epsilon$ se puede reformular $Y$:

$Y = \beta_1(ax) + \beta_1c + \beta_0 + \epsilon$

Donde la ordenada al origen est√° dada por $\beta_1c + \beta_0$.

### C√°lculo de desviaci√≥n vertical

$AlturaPunto - AlturaLinea = y_i -(\beta_1(ax_i) + \beta_1c + \beta_0)$

En este caso, la altura en un punto est√° dada por $y_i$, mientras que la altura de la l√≠nea est√° dada por $\beta_1(ax_i) + \beta_1c + \beta_0$.

$DV = y_i - (\beta_1ax_i + \beta_1c + \beta_0)$

### C√°lculo de estimadores

A partir del c√°lculo de la desviaci√≥n vertical puede definirse una funci√≥n $f$ para calcular la sumatoria de desviaciones al cuadrado:

$f(b_0, b_1) = \sum _{i=1}^n { [y_i - (\beta_1ax_i + \beta_1c + \beta_0)] }^2$

A continuaci√≥n se realizar√° el c√°lculo de las derivadas parciales:

$\dfrac {df(b_0,b_1)} {db_0} = \dfrac {d(\sum _{i=1}^n [y_i - (\beta_1ax_i + \beta_1c + \beta_0)]^2)} {db_0}$

$df(b_0, b_1) = -2 \sum_{i=1}^n (y_i - (b_1ax_i + b_1c + b_0))$

$\dfrac {df(b_0,b_1)} {db_1} = \dfrac {d(\sum _{i=1}^n [y_i - (\beta_1ax_i + \beta_1c + \beta_0)]^2)} {db_1}$

$\dfrac {df(b_0,b_1)} {db_1} = $ *// esta estaba complicada de resolver as√≠ que va a quedar ac√°*

### Estimador puntual $\hat\beta_0$

$\hat\beta_0 = -2\sum_{i=1}^n(y_i - (b_1ax_i + b_1c + b_0)) = 0$

$\sum_{i=1}^n(y_i - (b_1ax_i + b_1c + b_0)) = 0$

$\sum_{i=1}^n(y_i - b_1x_i - b_1c -b_0) = 0$

$\sum_{i=1}^ny_i - b_1\sum_{i=1}^nx_i - n.b_1.c - n.b_0 = 0$

$n.b_0 = \sum_{i=1}^ny_i - b_1\sum_{i=1}^nx_i - n.b_1.c$

$\hat\beta_0 = \dfrac {\sum_{i=1}^ny_i - b_1\sum_{i=1}^nx_i - n.b_1.c} {n}$

$\hat\beta_0 = \dfrac 1 n \sum_{i=1}^n y_i - \dfrac {b_1} n \sum_{i=1}^nx_i - b_1.c$

# 2.  Una cadena de supermercados financia un estudio sobre los gastos mensuales en alimentos, de familias de 4 miembros. La investigaci√≥n se limit√≥ a familias con ingresos netos entre \$688.000 y \$820.000, con lo cual se obtuvo la siguiente recta de estimaci√≥n $\hat y = 0,85ùë• ‚àí 18.000$.

## a. Estime los gastos en alimentos en un mes para una familia de 4 miembros con un ingreso de $700.000

* $y =$ gastos.
* $x =$ ingresos.

La recta dada para realizar la estimaci√≥n de los gastos es $\hat y = 0.85x - 18000$.

Como en este caso se sabe que $x = 700000$, puede calcularse la estimaci√≥n simplemente reemplazando dicha variable:

$\hat y = 0.85(700000) - 18000$

$\hat y = 595000 - 18000 = 577000$

## b. Uno de los directivos de la compa√±√≠a se preocupa por el hecho de que la ecuaci√≥n aparentemente indica que para una familia que tiene un ingreso de $12.000 no gastar√≠a nada en alimentos ¬øCu√°l ser√≠a su respuesta?

Nuevamente, se sabe que $x = 12000$, por lo que puede obtenerse una estimaci√≥n de los gastos alimenticios de la familia:

$\hat y = 0.85(12000) - 18000$

$\hat y = 10200 - 18000 = -7800$

Mi respuesta para el directivo ser√≠a que lamentablemente una familia con ese ingreso tendr√≠a que endeudarse para comer. Sin embargo, sabiendo que el an√°lisis se realiz√≥ a partir de familias con ingresos entre \$688.000 - \$820.000, no ser√≠a coherente utilizar la misma estimaci√≥n para una familia con un salario fuera de dicho rango, especialmente ya que se trata de un valor significativamente menor.

# 3. ?????????????????????????

# 4. Los siguientes datos corresponden a los tiempos relativos en segundos que tardaron en ejecutarse seis programas elegidos al azar en el entorno Windows y DOS:


| Windows | 2.5 | 7.1 | 5 | 8.5 | 7 | 8.1 |
| ------- | --- | --- | - | --- | - | --- |
|   DOS   | 2.3 | 7.1 | 4 | 8 | 6.6 | 5   |

## a. Realizar el gr√°fico de dispersi√≥n de los puntos

$x$: tiempo de ejecuci√≥n en Windows.

$y$: tiempo de ejecuci√≥n en DOS.

$n = 6$

```py
import matplotlib.pyplot as pyplot

x = [ 2.5, 7.1, 5, 8.5, 7, 8.1 ]
y = [ 2.3, 7.1, 4, 8, 6.6, 5 ]

pyplot.scatter(x, y)
pyplot.xlabel('Tiempo en Windows')
pyplot.ylabel('Tiempo en DOS')

pyplot.show()
```

## b. Si un programa tarda 6 segundos en ejecutarse en Windows, ¬øcu√°nto tardar√° en ejecutarse en DOS?

### C√°lculos previos

$\sum _{i=1}^n x_i = 38.2$

$\sum _{i=1}^n x_i^2 = 268.52$

$\overline x = 6.36$

$\sum_{i=1}^n y_i = 33$

$\overline y = 5.5$

$\sum _{i=1}^n x_iy_i = 230.86$

### Recta de ajuste

Para obtener el valor de $y$ para un valor determinado de $x$, se buscar√° obtener un estimador $\hat y$ usando el m√©todo de m√≠nimos cuadrados.

Partiendo de la l√≠nea de regresi√≥n estimada $\hat y = \hat\beta_0 + \hat\beta_1 x$:

$\hat\beta_1 = \dfrac {\sum(x_i - \overline x)(y_i - \overline y)} {\sum (x_i - \overline x)^2} = \dfrac {S_{xy}} {S_{xx}}$

$S_{xy} = \sum _{i=1}^n x_iy_i - \dfrac {\sum {x_i} \sum {y_i}} {n}$

$S_{xy} = 230.86 - \dfrac {38.2 * 33} {6}$

$S_{xy} = 230.86 - \dfrac {1260.6} {6} = 20.76$

$S_{xx} = \sum_{i=1}^n x_i^2 - \dfrac {(\sum x_i)^2} {n}$

$S_{xx} = 268.52 - \dfrac {38.2^2} 6$

$S_{xx} = 268.52 - \dfrac {1459.24} 6 = 25.31$

$\hat\beta_1 = \dfrac {20.76} {25.31} = 0.8202$

$\hat\beta_0 = \overline y - \hat\beta_1 \overline x$

$\hat\beta_0 = 5.5 - 0.8202 * 6.36 = 0.283528$

Volviendo a la recta $\hat y = \hat\beta_0 + \hat\beta_1 x$:

$\hat y = 0.283528 + 0.8202*x$

```py
import matplotlib.pyplot as pyplot

x = [ 2.5, 7.1, 5, 8.5, 7, 8.1 ]
y = [ 2.3, 7.1, 4, 8, 6.6, 5 ]

pyplot.scatter(x, y)
pyplot.xlabel("Tiempo en Windows")
pyplot.ylabel("Tiempo en DOS")

x_recta = [i for i in range(0, 10)]
y_recta = [0.283528 + 0.8202*x for x in x_recta]

pyplot.plot(x_recta, y_recta, label="Recta de ajuste", color="red")

pyplot.show()
```

### Resoluci√≥n del enunciado

A partir del estimador de $\hat y$ podemos deducir que cuando un programa tarde 6 segundos en Windows ($x = 6$), en DOS tardar√°:

$0.283528 + 0.8202*6 = 5.204$ segundos.

## c. Se estima que los tiempos de Windows mejorar√°n reduci√©ndose en un %10 en los pr√≥ximos a√±os, estime la recta de regresi√≥n considerando esta mejora. Suponga que los tiempos de DOS no se modifican.

Considerando la mejora, los valores de ejecuci√≥n en Windows pasar√≠an a ser el %90 de lo que eran antes.

### C√°lculos previos

$\sum _{i=1}^n x_i = 34.38$

$\sum _{i=1}^n x_i^2 = 217.5012$

$\overline x = 5.73$

$\sum_{i=1}^n y_i = 33$

$\overline y = 5.5$

$\sum _{i=1}^n x_iy_i = 207.7773$

### Recta de ajuste

Partiendo de la l√≠nea de regresi√≥n estimada $\hat y = \hat\beta_0 + \hat\beta_1 x$:

$\hat\beta_1 = \dfrac {\sum(x_i - \overline x)(y_i - \overline y)} {\sum (x_i - \overline x)^2} = \dfrac {S_{xy}} {S_{xx}}$

$S_{xy} = \sum _{i=1}^n x_iy_i - \dfrac {\sum {x_i} \sum {y_i}} {n}$

$S_{xy} = 207.7773 - \dfrac {34.38 * 33} {6}$

$S_{xy} = 207.7773 - \dfrac {1134.54} {6} = 18.6873$

$S_{xx} = \sum_{i=1}^n x_i^2 - \dfrac {(\sum x_i)^2} {n}$

$S_{xx} = 217.5012 - \dfrac {34.38^2} 6$

$S_{xx} = 217.5012 - \dfrac {1181.98} 6 = 20.5038$

$\hat\beta_1 = \dfrac {18.6873} {20.5038} = 0.9114$

$\hat\beta_0 = \overline y - \hat\beta_1 \overline x$

$\hat\beta_0 = 5.5 - 0.9114 * 5.73 = 0.27763$

### Resoluci√≥n del enunciado

Volviendo a la recta $\hat y = \hat\beta_0 + \hat\beta_1 x$, asumiendo la mejora del 10% esta pasar√≠a a ser:

$\hat y = 0.27763 + 0.9114*x$

*// es la manera m√°s correcta calcular todos los estimadores de nuevo?*

# 5. En la tabla siguiente se muestra la variable $y$ (el rendimiento de un sistema inform√°tico) respecto a la variable $x$ (n√∫mero de buffers). Se quiere asjutar la variable $y$ como funci√≥n de $x$:

| $x$ | 5 | 10 | 15 | 20 | 25 | 5 | 10 | 15 | 20 | 25 | 5 | 10 | 15 | 20 | 25 |
| --- | - | -- | -- | -- | -- | - | -- | -- | -- | -- | - | -- | -- | -- | -- |
| $y$ | 9.6 | 20.1 | 29.9 | 39.1 | 50.0 | 9.6 | 19.4 | 29.7 | 40.3 | 49.9 | 10.7 | 21.3 | 30.7 | 41.8 | 51.2 |

## a. Realizar el an√°lisis de regresi√≥n de datos (estimaci√≥n de recta, test de hip√≥tesis, indicadores).

$n = 15$

$x =$ cantidad de buffers.

$y =$ rendimiento de un sistema inform√°tico.

*// no termino de entender a qu√© se refiere con "rendimiento". es tiempo de ejecuci√≥n? uso de memoria? de cpu?*

### Estimaci√≥n de la recta

$\hat y = \hat\beta_0 + \hat\beta_1 x$

$\hat\beta_1 = \dfrac {S_{xy}} {S_{xx}}$

$S_{xy} = \sum_{i=1}^n x_iy_i - \dfrac {\sum x_i \sum y_i} n$

$S_{xy} = 8313.5 - \dfrac {225*453.3} {15}$

$S_{xy} = 8313.5 - 6799.5 = 1514$

$S_{xx} = \sum_{i=1}^n x_i^2 - \dfrac {(\sum x_i)^2} n$

$S_{xx} = 4125 - \dfrac {225^2} {15}$

$S_{xx} = 4125 - 3375 = 750$

$\hat\beta_1 = \dfrac {1514} {750} = 2.0186$

$\hat\beta_0 = \overline y - \hat\beta_1 \overline x$

$\hat\beta_0 = 30.219 - 2.0186 * 15 = -0.06$

$\hat y = -0.06 + 2.0186*x$

*// no le ten√≠a nada de fe pero la recta qued√≥ bastante bien*

```py
import matplotlib.pyplot as pyplot

x = [ 5, 10, 15, 20, 25, 5, 10, 15, 20, 25, 5, 10, 15, 20, 25 ]
y = [ 9.6, 20.1, 29.9, 39.1, 50.0, 9.6, 19.4, 29.7, 40.3, 49.9, 10.7, 21.3, 30.7, 41.8, 51.2 ]

x_recta = [i for i in range(0,30)]
y_recta = [-0.06 + 2.0186*el for el in x_recta]

pyplot.scatter(x, y)
pyplot.xlabel("Cantidad de buffers")
pyplot.ylabel("Rendimiento del SI")

pyplot.plot(x_recta, y_recta, label="Recta de ajuste", color="red")

pyplot.show()
```

*// no entiendo c√≥mo tendr√≠a que hacer los test de hip√≥tesis üëΩ cu√°l ser√≠a la constante para hacer las hip√≥tesis?*

## b. Comentar los siguientes resultados:

### Recta de regresi√≥n del rendimiento del SI frente al n√∫mero de buffers e interpretaci√≥n de los coeficientes.

La recta de regresi√≥n $\hat y = -0.06 + 2.0186*x$ est√° muy buena porque tiene muy poca variaci√≥n. Esto puede calcularse con el estimador de variabilidad:

$\hat\sigma^2 = \dfrac {SCE} {n-2}$

$SCE = S_{yy} - \dfrac {(S_{xy})^2} {S_{xx}}$ 

$SCE = 3064.324 - \dfrac {(1514^2)} {750}$

$\hat\sigma^2 = \dfrac {8.0626} {13}$

$\hat\sigma^2 = 0.6202$

### Contraste de hip√≥tesis sobre la pendiente de la pendiente de la recta.

*// ni hice hip√≥tesis je*

### Coeficiente de determinaci√≥n y correlaci√≥n lineal.

$R^2 = 1 - \dfrac {SCE} {STC}$

$STC = S_{yy} = 3064.324$

$R^2 = 1 - \dfrac {8.0626} {3064.324}$

$R^2 = 1 - 0.00263$

$R^2 = 0.99736$

El coeficiente de determinaci√≥n es muy cercano a 1, por lo que es muy preciso para explicar la variaci√≥n de la variable $y$.

$r = \sqrt {R^2}$

$r = \sqrt {0.99736} =  \pm 0.99868$

$\hat\beta_1$ es un valor positivo, por lo que $r = 0.99868$. Esto implica que hay una relaci√≥n directa entre $x$ e $y$, en la que $y$ aumenta con el valor de $x$.